import torch
import torch_directml

print("Torch:", torch.__version__)
print("CUDA disponible:", torch.cuda.is_available())

try:
    dml = torch_directml.device()
    print("DirectML OK:", dml)
except Exception as e:
    print("DirectML no disponible:", e)


def obtener_device():
    if torch.cuda.is_available():
        try:
            compute = torch.cuda.get_device_capability()
            if compute >= (12, 0):
                print("âš  GPU detectada pero PyTorch aÃºn no soporta la arquitectura sm_120")
                print("â¡ Se utilizarÃ¡ CPU temporalmente para evitar fallos.")
                return torch.device("cpu")
            else:
                print("ğŸ”§ Usando CUDA")
                return torch.device("cuda")
        except:
            print("ğŸ”§ Usando CPU")
            return torch.device("cpu")
    else:
        try:
            print("ğŸ”§ Usando DirectML como aceleraciÃ³n alternativa.") #Esto me imprime al usar mi vieja Notebook
            return torch_directml.device()
        except:
            print("ğŸ”§ No hay aceleraciÃ³n disponible, usando CPU.")
            return torch.device("cpu")
        
        
def detectar_backend():
    # 1. Intentar CUDA (solo si PyTorch real estÃ¡ instalado)
    try:
        import torch
        if hasattr(torch, "cuda") and torch.cuda.is_available():
            print("âš¡ Detectado backend: CUDA (ASUS TUF)")
            return "cuda"


    except:
        pass

    # 2. Intentar DirectML
    if importlib.util.find_spec("torch_directml") is not None:
        print("ğŸ’  Detectado backend: DirectML (Notebook)")
        return "dml"



    # 3. CPU puro
    print("ğŸ–¥ï¸ Detectado backend: CPU (modo bÃ¡sico)")
    return "cpu"